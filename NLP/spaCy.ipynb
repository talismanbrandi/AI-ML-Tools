{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% https://www.kaggle.com/matleonard/intro-to-nlp\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.matcher import PhraseMatcher\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from spacy.util import minibatch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Tea\n",
      "is\n",
      "healthy\n",
      "and\n",
      "calming\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "think\n",
      "?\n",
      "Token \t\tLemma \t\tStopword\n",
      "----------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalming\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tnot\t\tTrue\n",
      "you\t\t-PRON-\t\tTrue\n",
      "think\t\tthink\t\tFalse\n",
      "?\t\t?\t\tFalse\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "doc = nlp(\"Tea is healthy and calming, don't you think?\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    \n",
    "print(f'Token \\t\\tLemma \\t\\tStopword'.format('Token', 'Lemma', 'Stopword'))\n",
    "print('-'*40)\n",
    "for token in doc:\n",
    "    print(f'{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n",
      "TerminologyList iPhone 11\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "matcher.add('TerminologyList', None, *patterns)\n",
    "\n",
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\")\n",
    "\n",
    "matches = matcher(text_doc)\n",
    "print(matches)\n",
    "\n",
    "match_id, start, end = matches[0]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start:end])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_json('data/restaurant.json')\n",
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "         \"Prosciutto\", \"Salami\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Yelp Review Exercise\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2:\t Purista\n",
      "16:\t prosciutto\n",
      "58:\t meatball\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "index = 14\n",
    "test_text = data.text.iloc[index]\n",
    "review_doc = nlp(test_text)\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "menu_tokens_list = [nlp(items) for items in menu]\n",
    "\n",
    "matcher.add('MENU', None, *menu_tokens_list)\n",
    "matches = matcher(review_doc)\n",
    "\n",
    "# print(f\"Token number {matches[1]}: {review_doc[matches[1]:matches[2]]}\")\n",
    "for match in matches:\n",
    "    print(f\"{match[1]}:\\t\", review_doc[match[1]:match[2]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "item_ratings = defaultdict(list)\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    doc = nlp(review.text)\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    found_items = [doc[match[1]:match[2]] for match in matches]\n",
    "    for item in found_items:\n",
    "        item_ratings[str(item).lower()].append(review.stars)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "corned beef              : 5.00\n",
      "turkey breast            : 5.00\n",
      "fettuccini alfredo       : 5.00\n",
      "artichoke salad          : 5.00\n",
      "steak and cheese         : 4.89\n",
      "reuben                   : 4.80\n",
      "pastrami                 : 4.69\n",
      "chicken salad            : 4.67\n",
      "purista                  : 4.64\n",
      "prosciutto               : 4.62\n",
      "chicken pesto            : 4.57\n",
      "calzones                 : 4.55\n",
      "grilled veggie           : 4.50\n",
      "chicken spinach salad    : 4.50\n",
      "gnocchi                  : 4.49\n",
      "cheese steak             : 4.45\n",
      "mac and cheese           : 4.44\n",
      "chicken parmigiana       : 4.44\n",
      "lasagna                  : 4.41\n",
      "pizzas                   : 4.39\n",
      "pasta                    : 4.39\n",
      "cannoli                  : 4.34\n",
      "cheesesteak              : 4.34\n",
      "pizza                    : 4.30\n",
      "calzone                  : 4.26\n",
      "tiramisu                 : 4.26\n",
      "chicken parmesan         : 4.24\n",
      "ziti                     : 4.23\n",
      "salami                   : 4.22\n",
      "italian sausage          : 4.21\n",
      "macaroni                 : 4.17\n",
      "chicken parm             : 4.16\n",
      "roast beef               : 4.14\n",
      "portobello               : 4.11\n",
      "meatball                 : 4.08\n",
      "garlic bread             : 4.02\n",
      "tuna salad               : 4.00\n",
      "italian beef             : 4.00\n",
      "eggplant                 : 3.97\n",
      "italian combo            : 3.91\n",
      "spaghetti                : 3.85\n",
      "turkey sandwich          : 3.80\n",
      "chicken cutlet           : 3.55\n",
      "chicken cutlet\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "average_item_ratings = defaultdict(list)\n",
    "for key in item_ratings:\n",
    "    average_item_ratings[key] = np.mean(item_ratings[key])\n",
    "\n",
    "for key, value in reversed(sorted(average_item_ratings.items(), key=lambda item: item[1])):\n",
    "    print(\"{:25}: {:3.2f}\".format(key, value))\n",
    "    \n",
    "worst_item = sorted(average_item_ratings, key=average_item_ratings.get)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "pizza                      358\n",
      "pasta                      255\n",
      "meatball                   163\n",
      "cheesesteak                146\n",
      "calzone                    110\n",
      "eggplant                    95\n",
      "cannoli                     89\n",
      "cheese steak                88\n",
      "lasagna                     83\n",
      "purista                     67\n",
      "prosciutto                  63\n",
      "chicken parm                58\n",
      "italian sausage             57\n",
      "garlic bread                46\n",
      "gnocchi                     45\n",
      "spaghetti                   41\n",
      "calzones                    38\n",
      "pizzas                      33\n",
      "salami                      32\n",
      "chicken pesto               30\n",
      "italian beef                29\n",
      "tiramisu                    27\n",
      "ziti                        26\n",
      "italian combo               22\n",
      "chicken parmesan            21\n",
      "chicken parmigiana          18\n",
      "mac and cheese              18\n",
      "portobello                  18\n",
      "pastrami                    16\n",
      "chicken cutlet              11\n",
      "steak and cheese             9\n",
      "roast beef                   7\n",
      "fettuccini alfredo           6\n",
      "grilled veggie               6\n",
      "macaroni                     6\n",
      "chicken salad                6\n",
      "turkey sandwich              5\n",
      "tuna salad                   5\n",
      "artichoke salad              5\n",
      "reuben                       5\n",
      "chicken spinach salad        2\n",
      "corned beef                  2\n",
      "turkey breast                1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}\n",
    "item_counts = sorted(counts, key=counts.get, reverse=True)\n",
    "for item in item_counts:\n",
    "    print(f\"{item:25}{counts[item]:>5}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Worst rated menu items:\n",
      "chicken cutlet            AR: 3.55 \tC: 11\n",
      "turkey sandwich           AR: 3.80 \tC: 5\n",
      "spaghetti                 AR: 3.85 \tC: 41\n",
      "italian combo             AR: 3.91 \tC: 22\n",
      "eggplant                  AR: 3.97 \tC: 95\n",
      "italian beef              AR: 4.00 \tC: 29\n",
      "tuna salad                AR: 4.00 \tC: 5\n",
      "garlic bread              AR: 4.02 \tC: 46\n",
      "meatball                  AR: 4.08 \tC: 163\n",
      "portobello                AR: 4.11 \tC: 18\n",
      "\n",
      "Best rated menu items:\n",
      "corned beef               AR: 5.00 \tC: 2\n",
      "turkey breast             AR: 5.00 \tC: 1\n",
      "fettuccini alfredo        AR: 5.00 \tC: 6\n",
      "artichoke salad           AR: 5.00 \tC: 5\n",
      "steak and cheese          AR: 4.89 \tC: 9\n",
      "reuben                    AR: 4.80 \tC: 5\n",
      "pastrami                  AR: 4.69 \tC: 16\n",
      "chicken salad             AR: 4.67 \tC: 6\n",
      "purista                   AR: 4.64 \tC: 67\n",
      "prosciutto                AR: 4.62 \tC: 63\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sorted_ratings = sorted(average_item_ratings, key=average_item_ratings.get)\n",
    "print('Worst rated menu items:')\n",
    "for item in sorted_ratings[:10]:\n",
    "    print(f'{item:25} AR: {average_item_ratings[item]:3.2f} \\tC: {counts[item]}')\n",
    "    \n",
    "print('\\nBest rated menu items:')\n",
    "for item in reversed(sorted_ratings[-10:]):\n",
    "    print(f'{item:25} AR: {average_item_ratings[item]:3.2f} \\tC: {counts[item]}')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Least reviewed menuitems:\n",
      "turkey breast             C: 1       AR: 5.00\n",
      "chicken spinach salad     C: 2       AR: 4.50\n",
      "corned beef               C: 2       AR: 5.00\n",
      "turkey sandwich           C: 5       AR: 3.80\n",
      "tuna salad                C: 5       AR: 4.00\n",
      "artichoke salad           C: 5       AR: 5.00\n",
      "reuben                    C: 5       AR: 4.80\n",
      "fettuccini alfredo        C: 6       AR: 5.00\n",
      "grilled veggie            C: 6       AR: 4.50\n",
      "macaroni                  C: 6       AR: 4.17\n",
      "\n",
      "Most reviwed menu items:\n",
      "pizza                     C: 358     AR: 4.30\n",
      "pasta                     C: 255     AR: 4.39\n",
      "meatball                  C: 163     AR: 4.08\n",
      "cheesesteak               C: 146     AR: 4.34\n",
      "calzone                   C: 110     AR: 4.26\n",
      "eggplant                  C: 95      AR: 3.97\n",
      "cannoli                   C: 89      AR: 4.34\n",
      "cheese steak              C: 88      AR: 4.45\n",
      "lasagna                   C: 83      AR: 4.41\n",
      "purista                   C: 67      AR: 4.64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sorted_counts = sorted(counts, key=counts.get)\n",
    "print('Least reviewed menuitems:')\n",
    "for item in sorted_counts[:10]:\n",
    "    print(f'{item:25} C: {counts[item]:<7} AR: {average_item_ratings[item]:3.2f}')\n",
    "    \n",
    "print('\\nMost reviwed menu items:')\n",
    "for item in reversed(sorted_counts[-10:]):\n",
    "    print(f'{item:25} C: {counts[item]:<7} AR: {average_item_ratings[item]:3.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "spam = pd.read_csv('data/spam.csv')\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "textcat = nlp.create_pipe('textcat', config={'exclusive_classes': True, 'architechture': 'bow'})\n",
    "nlp.add_pipe(textcat)\n",
    "\n",
    "textcat.add_label('ham')\n",
    "textcat.add_label('spam')\n",
    "\n",
    "train_texts = spam['text'].values\n",
    "train_labels = [{'cats': {'ham': label == 'ham', 'spam': label == 'spam'}}\n",
    "                for label in spam['label']]\n",
    "\n",
    "train_data = list(zip(train_texts, train_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Lesson 2\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "batches = minibatch(train_data, size=8)\n",
    "\n",
    "for batch in batches:\n",
    "    text, labels = zip(*batch)\n",
    "    nlp.update(text, labels, sgd=optimizer)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'textcat': 0.21975726346467503}\n",
      "{'textcat': 0.318620875587339}\n",
      "{'textcat': 0.39770351629094536}\n",
      "{'textcat': 0.43069386248883706}\n",
      "{'textcat': 0.45787767076693225}\n",
      "{'textcat': 0.45834652515703533}\n",
      "{'textcat': 0.45834678759302133}\n",
      "{'textcat': 0.4583468100206913}\n",
      "{'textcat': 0.4583468193062615}\n",
      "{'textcat': 0.45834682363745427}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "losses = {}\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    for batch in batches:\n",
    "        text, labels = zip(*batch)\n",
    "        nlp.update(text, labels, sgd=optimizer, losses=losses)\n",
    "    print(losses)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[9.9999940e-01 6.2277752e-07]\n",
      " [3.3817263e-04 9.9966180e-01]]\n",
      "['ham', 'spam']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "texts = [\"Are you ready for the tea party????? It's gonna be wild\",\n",
    "         \"URGENT Reply to this message for GUARANTEED FREE TEA\" ]\n",
    "\n",
    "docs = [nlp.tokenizer(text) for text in texts]\n",
    "\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(docs)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "predicted_lables = scores.argmax(axis=1)\n",
    "print([textcat.labels[label] for label in predicted_lables])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Texts from training data\n",
      "------\n",
      "[\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\"\n",
      " \"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\"]\n",
      "\n",
      "Labels from training data\n",
      "------\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[{'cats': {'POSITIVE': True, 'NEGATIVE': False}},\n {'cats': {'POSITIVE': True, 'NEGATIVE': False}}]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "\n",
    "def load_data(csv_file, split=0.9):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Shuffle data\n",
    "    train_data = data.sample(frac=1, random_state=7)\n",
    "    \n",
    "    texts = train_data.text.values\n",
    "    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n",
    "              for y in train_data.sentiment.values]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n",
    "    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n",
    "    \n",
    "    return texts[:split], train_labels, texts[split:], val_labels\n",
    "\n",
    "train_texts, train_labels, val_texts, val_labels = load_data('data/yelp_ratings.csv')\n",
    "\n",
    "print('Texts from training data\\n------')\n",
    "print(train_texts[:2])\n",
    "print('\\nLabels from training data\\n------')\n",
    "train_labels[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "8.859361211946009\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "textcat = nlp.create_pipe('textcat', config={'exclusive_classes': True, 'architechture': 'bow'})\n",
    "nlp.add_pipe(textcat)\n",
    "\n",
    "textcat.add_label('NEGATIVE')\n",
    "textcat.add_label('POSITIVE')\n",
    "\n",
    "def train(model, train_data, optimizer):\n",
    "    \n",
    "    losses = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    batches = minibatch(train_data, size=8)\n",
    "    for batch in batches:\n",
    "        texts, labels = zip(*batch)\n",
    "        model.update(texts, labels, sgd=optimizer, losses=losses)\n",
    "    return losses\n",
    "        \n",
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "losses = train(nlp, train_data, optimizer)\n",
    "print(losses['textcat'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'NEGATIVE': 0.9836472868919373, 'POSITIVE': 0.016352694481611252}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "text = \"This tea cup was full of holes. Do not recommend.\"\n",
    "doc = nlp(text)\n",
    "print(doc.cats)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "POSITIVE: Came over and had their \"Pick 2\" lunch combo and chose their best selling 1/2 chicken sandwich with quinoa.  Both were tasty, the chicken salad is a bit creamy but was perfect with quinoa on the side.  This is a good lunch joint, casual and clean! \n",
      "\n",
      "POSITIVE: Went here last night and got oysters, fried okra, fries, and onion rings. I cannot complain. The portions were great and tasty!!! I will definitely be back for more. I cannot wait to try the crawfish boudin and soft shell crab. \n",
      "\n",
      "POSITIVE: This restaurant was fantastic! \n",
      "The concept of eating without vision was intriguing. The dinner was filled with laughs and good conversation. \n",
      "\n",
      "We were lead in a line to our table and each person to their seat. This was not just dark but you could not see something right in front of your face. \n",
      "\n",
      "The waiters/waitresses were all blind and allowed us to see how aware you need to be without the vision. \n",
      "\n",
      "Taking away one sense is said to increase your other senses so as taste and hearing which I believed to be true in this experience. \n",
      "\n",
      "The meal was extremely delicious. I had the chicken and it was cooked to perfection. I also had a surprise beer which was a nice surprise. \n",
      "\n",
      "The whole experience was unlike anything I have ever done and I hope this spreads to other cities. \n",
      "\n",
      "A must do! \n",
      "\n",
      "NEGATIVE: They won't book new patients for same day appointments. My dog is sick but it's not necessarily urgent so I asked when I would be able to book an appointment and was told \"new patients book out at least 6 weeks in advance\" so just a heads up this seems like a great vet from other reviews but it'll be hard to get in their system to know \n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def predict(model, texts):\n",
    "    docs = [model.tokenizer(text) for text in texts]\n",
    "    \n",
    "    textcat = model.get_pipe('textcat')\n",
    "    scores, _ = textcat.predict(docs)\n",
    "\n",
    "    predicted_labels = scores.argmax(axis=1)\n",
    "    return predicted_labels\n",
    "\n",
    "texts = val_texts[34:38]\n",
    "predictions = predict(nlp, texts)\n",
    "\n",
    "for p, t in zip(predictions, texts):\n",
    "    print(f\"{textcat.labels[p]}: {t} \\n\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 0.9499\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def evaluate(model, tt, ll):\n",
    "    \"\"\" Returns the accuracy of a TextCategorizer model. \n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        model: ScaPy model with a TextCategorizer\n",
    "        texts: Text samples, from load_data function\n",
    "        labels: True labels, from load_data function\n",
    "\n",
    "    \"\"\"\n",
    "    predicted_class = predict(model, tt)\n",
    "    true_class = [int(each['cats']['POSITIVE']) for each in ll]\n",
    "    correct_predictions = predicted_class == true_class\n",
    "        \n",
    "    accuracy = correct_predictions.mean()\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 3.685 \t Accuracy: 0.946\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    losses = train(nlp, train_data, optimizer)\n",
    "    accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}